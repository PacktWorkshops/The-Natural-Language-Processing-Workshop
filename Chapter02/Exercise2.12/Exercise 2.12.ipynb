{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Extracting General Features from Text"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nfrom string import punctuation\nimport nltk\n\nnltk.download('tagsets')\nnltk.download('punkt')\nfrom nltk.data import load\n\nnltk.download('averaged_perceptron_tagger')\nfrom nltk import pos_tag\nfrom nltk import word_tokenize\nfrom collections import Counter","execution_count":1,"outputs":[{"output_type":"stream","text":"[nltk_data] Downloading package tagsets to /home/jovyan/nltk_data...\n[nltk_data]   Package tagsets is already up-to-date!\n[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n[nltk_data]   Unzipping tokenizers/punkt.zip.\n[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     /home/jovyan/nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_tagsets():\n    tagdict = load('help/tagsets/upenn_tagset.pickle')\n    return list(tagdict.keys())\n \ntag_list = get_tagsets()\n \nprint(tag_list)","execution_count":2,"outputs":[{"output_type":"stream","text":"['LS', 'TO', 'VBN', \"''\", 'WP', 'UH', 'VBG', 'JJ', 'VBZ', '--', 'VBP', 'NN', 'DT', 'PRP', ':', 'WP$', 'NNPS', 'PRP$', 'WDT', '(', ')', '.', ',', '``', '$', 'RB', 'RBR', 'RBS', 'VBD', 'IN', 'FW', 'RP', 'JJR', 'JJS', 'PDT', 'MD', 'VB', 'WRB', 'NNP', 'EX', 'NNS', 'SYM', 'CC', 'CD', 'POS']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This method will count occurrence of pos tags in each sentence.\ndef get_pos_occurrence_freq(data, tag_list):\n    # Get list of sentences in text_list\n    text_list = data.text\n    \n    # create empty dataframe\n    feature_df = pd.DataFrame(columns=tag_list)\n    for text_line in text_list:\n        \n        # get pos tags of each word.\n        pos_tags = [j for i, j in pos_tag(word_tokenize(text_line))]\n        \n        # create a dict of pos tags and their frequency in given sentence.\n        row = dict(Counter(pos_tags))\n        feature_df = feature_df.append(row, ignore_index=True)\n    feature_df.fillna(0, inplace=True)\n    return feature_df\n\ntag_list = get_tagsets()\n\ndata = pd.read_csv('../data/data.csv', header=0)\nfeature_df = get_pos_occurrence_freq(data, tag_list)\nfeature_df.head()","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"    LS   TO  VBN   ''   WP   UH  VBG   JJ  VBZ   --  ...   MD   VB  WRB  NNP  \\\n0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n3  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  ...  0.0  0.0  0.0  0.0   \n4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  ...  0.0  0.0  0.0  0.0   \n\n    EX  NNS  SYM   CC   CD  POS  \n0  0.0  1.0  0.0  0.0  0.0  0.0  \n1  0.0  1.0  0.0  0.0  0.0  0.0  \n2  0.0  0.0  0.0  0.0  0.0  0.0  \n3  0.0  0.0  0.0  0.0  0.0  0.0  \n4  0.0  0.0  0.0  0.0  0.0  0.0  \n\n[5 rows x 45 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LS</th>\n      <th>TO</th>\n      <th>VBN</th>\n      <th>''</th>\n      <th>WP</th>\n      <th>UH</th>\n      <th>VBG</th>\n      <th>JJ</th>\n      <th>VBZ</th>\n      <th>--</th>\n      <th>...</th>\n      <th>MD</th>\n      <th>VB</th>\n      <th>WRB</th>\n      <th>NNP</th>\n      <th>EX</th>\n      <th>NNS</th>\n      <th>SYM</th>\n      <th>CC</th>\n      <th>CD</th>\n      <th>POS</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 45 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def add_punctuation_count(feature_df, data):\n    # The below code line will find the intersection of set\n    # of punctuations in text and punctuation set\n    # imported from string module of python and find the length of\n    # intersection set in each row and add it to column `num_of_unique_punctuations`\n    # of data frame.\n \n    feature_df['num_of_unique_punctuations'] = data['text']. \\\n        apply(lambda x: len(set(x).intersection(set(punctuation))))\n    return feature_df\n \nfeature_df = add_punctuation_count(feature_df, data)\n \nfeature_df['num_of_unique_punctuations'].head()","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"0    0\n1    0\n2    1\n3    1\n4    0\nName: num_of_unique_punctuations, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_capitalized_word_count(feature_df, data):\n    # The below code line will tokenize text in every row and\n    # create a set of only capital words, then find the length of\n    # this set and add it to the column `number_of_capital_words`\n    # of dataframe.\n \n    feature_df['number_of_capital_words'] = data['text'].\\\n        apply(lambda x: len([word for word in word_tokenize(str(x)) if word[0].isupper()]))\n    return feature_df\n \nfeature_df = get_capitalized_word_count(feature_df, data)\n \nfeature_df['number_of_capital_words'].head()","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"0    1\n1    1\n2    1\n3    1\n4    1\nName: number_of_capital_words, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_small_word_count(feature_df, data):\n    # The below code line will tokenize text in every row and\n    # create a set of only small words, then find the length of\n    # this set and add it to the column `number_of_small_words`\n    # of dataframe.\n \n    feature_df['number_of_small_words'] = data['text'].\\\n        apply(lambda x: len([word for word in word_tokenize(str(x)) if word[0].islower()]))\n    return feature_df","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_df = get_small_word_count(feature_df, data)\nfeature_df['number_of_small_words'].head()","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"0    4\n1    3\n2    7\n3    3\n4    2\nName: number_of_small_words, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_number_of_alphabets(feature_df, data):\n    # The below code line will break the text line in a list of\n    # characters in each row and add the count of that list into\n    # the columns `number_of_alphabets`\n \n    feature_df['number_of_alphabets'] = data['text']. \\\n        apply(lambda x: len([ch for ch in str(x) if ch.isalpha()]))\n    return feature_df\nfeature_df = get_number_of_alphabets(feature_df, data)\nfeature_df['number_of_alphabets'].head()\n","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"0    19\n1    18\n2    28\n3    14\n4    13\nName: number_of_alphabets, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_number_of_digit_count(feature_df, data):\n    # The below code line will break the text line in a list of\n    # digits in each row and add the count of that list into\n    # the columns `number_of_digits`\n \n    feature_df['number_of_digits'] = data['text']. \\\n        apply(lambda x: len([ch for ch in str(x) if ch.isdigit()]))\n    return feature_df\nfeature_df = get_number_of_digit_count(feature_df, data)\nfeature_df['number_of_digits'].head()","execution_count":9,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"0    0\n1    0\n2    0\n3    0\n4    0\nName: number_of_digits, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_number_of_words(feature_df, data):\n    # The below code line will break the text line in a list of\n    # words in each row and add the count of that list into\n    # the columns `number_of_digits`\n \n    feature_df['number_of_words'] = data['text'].apply(lambda x\n                                                       : len(word_tokenize(str(x))))\n \n    return feature_df\n\nfeature_df = get_number_of_words(feature_df, data)\nfeature_df['number_of_words'].head()","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"0    5\n1    4\n2    9\n3    5\n4    3\nName: number_of_words, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_number_of_whitespaces(feature_df, data):\n    # The below code line will generate list of white spaces\n    # in each row and add the length of that list into\n    # the columns `number_of_white_spaces`\n \n    feature_df['number_of_white_spaces'] = data['text']. \\\n        apply(lambda x: len([ch for ch in str(x) if ch.isspace()]))\n \n    return feature_df\n \nfeature_df = get_number_of_whitespaces(feature_df, data)\nfeature_df['number_of_white_spaces'].head()","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"0    4\n1    3\n2    7\n3    3\n4    2\nName: number_of_white_spaces, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_df.head()","execution_count":12,"outputs":[{"output_type":"execute_result","execution_count":12,"data":{"text/plain":"    LS   TO  VBN   ''   WP   UH  VBG   JJ  VBZ   --  ...   CC   CD  POS  \\\n0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n3  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  ...  0.0  0.0  0.0   \n4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  ...  0.0  0.0  0.0   \n\n   num_of_unique_punctuations  number_of_capital_words  number_of_small_words  \\\n0                           0                        1                      4   \n1                           0                        1                      3   \n2                           1                        1                      7   \n3                           1                        1                      3   \n4                           0                        1                      2   \n\n   number_of_alphabets  number_of_digits  number_of_words  \\\n0                   19                 0                5   \n1                   18                 0                4   \n2                   28                 0                9   \n3                   14                 0                5   \n4                   13                 0                3   \n\n   number_of_white_spaces  \n0                       4  \n1                       3  \n2                       7  \n3                       3  \n4                       2  \n\n[5 rows x 52 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LS</th>\n      <th>TO</th>\n      <th>VBN</th>\n      <th>''</th>\n      <th>WP</th>\n      <th>UH</th>\n      <th>VBG</th>\n      <th>JJ</th>\n      <th>VBZ</th>\n      <th>--</th>\n      <th>...</th>\n      <th>CC</th>\n      <th>CD</th>\n      <th>POS</th>\n      <th>num_of_unique_punctuations</th>\n      <th>number_of_capital_words</th>\n      <th>number_of_small_words</th>\n      <th>number_of_alphabets</th>\n      <th>number_of_digits</th>\n      <th>number_of_words</th>\n      <th>number_of_white_spaces</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>4</td>\n      <td>19</td>\n      <td>0</td>\n      <td>5</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>18</td>\n      <td>0</td>\n      <td>4</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>7</td>\n      <td>28</td>\n      <td>0</td>\n      <td>9</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>14</td>\n      <td>0</td>\n      <td>5</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>13</td>\n      <td>0</td>\n      <td>3</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 52 columns</p>\n</div>"},"metadata":{}}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":2}