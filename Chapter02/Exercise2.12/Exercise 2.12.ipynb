{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting General Features from Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package tagsets to\n",
      "[nltk_data]     C:\\Users\\ankit.bhatia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package tagsets is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\ankit.bhatia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from string import punctuation\n",
    "import nltk\n",
    "\n",
    "nltk.download('tagsets')\n",
    "from nltk.data import load\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk import pos_tag\n",
    "from nltk import word_tokenize\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LS', 'TO', 'VBN', \"''\", 'WP', 'UH', 'VBG', 'JJ', 'VBZ', '--', 'VBP', 'NN', 'DT', 'PRP', ':', 'WP$', 'NNPS', 'PRP$', 'WDT', '(', ')', '.', ',', '``', '$', 'RB', 'RBR', 'RBS', 'VBD', 'IN', 'FW', 'RP', 'JJR', 'JJS', 'PDT', 'MD', 'VB', 'WRB', 'NNP', 'EX', 'NNS', 'SYM', 'CC', 'CD', 'POS']\n"
     ]
    }
   ],
   "source": [
    "def get_tagsets():\n",
    "    tagdict = load('help/tagsets/upenn_tagset.pickle')\n",
    "    return list(tagdict.keys())\n",
    " \n",
    "tag_list = get_tagsets()\n",
    " \n",
    "print(tag_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LS</th>\n",
       "      <th>TO</th>\n",
       "      <th>VBN</th>\n",
       "      <th>''</th>\n",
       "      <th>WP</th>\n",
       "      <th>UH</th>\n",
       "      <th>VBG</th>\n",
       "      <th>JJ</th>\n",
       "      <th>VBZ</th>\n",
       "      <th>--</th>\n",
       "      <th>...</th>\n",
       "      <th>MD</th>\n",
       "      <th>VB</th>\n",
       "      <th>WRB</th>\n",
       "      <th>NNP</th>\n",
       "      <th>EX</th>\n",
       "      <th>NNS</th>\n",
       "      <th>SYM</th>\n",
       "      <th>CC</th>\n",
       "      <th>CD</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    LS   TO  VBN   ''   WP   UH  VBG   JJ  VBZ   --  ...   MD   VB  WRB  NNP  \\\n",
       "0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "\n",
       "    EX  NNS  SYM   CC   CD  POS  \n",
       "0  0.0  1.0  0.0  0.0  0.0  0.0  \n",
       "1  0.0  1.0  0.0  0.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This method will count occurrence of pos tags in each sentence.\n",
    "def get_pos_occurrence_freq(data, tag_list):\n",
    "    # Get list of sentences in text_list\n",
    "    text_list = data.text\n",
    "    \n",
    "    # create empty dataframe\n",
    "    feature_df = pd.DataFrame(columns=tag_list)\n",
    "    for text_line in text_list:\n",
    "        \n",
    "        # get pos tags of each word.\n",
    "        pos_tags = [j for i, j in pos_tag(word_tokenize(text_line))]\n",
    "        \n",
    "        # create a dict of pos tags and their frequency in given sentence.\n",
    "        row = dict(Counter(pos_tags))\n",
    "        feature_df = feature_df.append(row, ignore_index=True)\n",
    "    feature_df.fillna(0, inplace=True)\n",
    "    return feature_df\n",
    "\n",
    "tag_list = get_tagsets()\n",
    "\n",
    "data = pd.read_csv('../data/data.csv', header=0)\n",
    "feature_df = get_pos_occurrence_freq(data, tag_list)\n",
    "feature_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    1\n",
       "3    1\n",
       "4    0\n",
       "Name: num_of_unique_punctuations, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_punctuation_count(feature_df, data):\n",
    "    # The below code line will find the intersection of set\n",
    "    # of punctuations in text and punctuation set\n",
    "    # imported from string module of python and find the length of\n",
    "    # intersection set in each row and add it to column `num_of_unique_punctuations`\n",
    "    # of data frame.\n",
    " \n",
    "    feature_df['num_of_unique_punctuations'] = data['text']. \\\n",
    "        apply(lambda x: len(set(x).intersection(set(punctuation))))\n",
    "    return feature_df\n",
    " \n",
    "feature_df = add_punctuation_count(feature_df, data)\n",
    " \n",
    "feature_df['num_of_unique_punctuations'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: number_of_capital_words, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_capitalized_word_count(feature_df, data):\n",
    "    # The below code line will tokenize text in every row and\n",
    "    # create a set of only capital words, then find the length of\n",
    "    # this set and add it to the column `number_of_capital_words`\n",
    "    # of dataframe.\n",
    " \n",
    "    feature_df['number_of_capital_words'] = data['text'].\\\n",
    "        apply(lambda x: len([word for word in word_tokenize(str(x)) if word[0].isupper()]))\n",
    "    return feature_df\n",
    " \n",
    "feature_df = get_capitalized_word_count(feature_df, data)\n",
    " \n",
    "feature_df['number_of_capital_words'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_small_word_count(feature_df, data):\n",
    "    # The below code line will tokenize text in every row and\n",
    "    # create a set of only small words, then find the length of\n",
    "    # this set and add it to the column `number_of_small_words`\n",
    "    # of dataframe.\n",
    " \n",
    "    feature_df['number_of_small_words'] = data['text'].\\\n",
    "        apply(lambda x: len([word for word in word_tokenize(str(x)) if word[0].islower()]))\n",
    "    return feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4\n",
       "1    3\n",
       "2    7\n",
       "3    3\n",
       "4    2\n",
       "Name: number_of_small_words, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_df = get_small_word_count(feature_df, data)\n",
    "feature_df['number_of_small_words'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    19\n",
       "1    18\n",
       "2    28\n",
       "3    14\n",
       "4    13\n",
       "Name: number_of_alphabets, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_number_of_alphabets(feature_df, data):\n",
    "    # The below code line will break the text line in a list of\n",
    "    # characters in each row and add the count of that list into\n",
    "    # the columns `number_of_alphabets`\n",
    " \n",
    "    feature_df['number_of_alphabets'] = data['text']. \\\n",
    "        apply(lambda x: len([ch for ch in str(x) if ch.isalpha()]))\n",
    "    return feature_df\n",
    "feature_df = get_number_of_alphabets(feature_df, data)\n",
    "feature_df['number_of_alphabets'].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: number_of_digits, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_number_of_digit_count(feature_df, data):\n",
    "    # The below code line will break the text line in a list of\n",
    "    # digits in each row and add the count of that list into\n",
    "    # the columns `number_of_digits`\n",
    " \n",
    "    feature_df['number_of_digits'] = data['text']. \\\n",
    "        apply(lambda x: len([ch for ch in str(x) if ch.isdigit()]))\n",
    "    return feature_df\n",
    "feature_df = get_number_of_digit_count(feature_df, data)\n",
    "feature_df['number_of_digits'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5\n",
       "1    4\n",
       "2    9\n",
       "3    5\n",
       "4    3\n",
       "Name: number_of_words, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_number_of_words(feature_df, data):\n",
    "    # The below code line will break the text line in a list of\n",
    "    # words in each row and add the count of that list into\n",
    "    # the columns `number_of_digits`\n",
    " \n",
    "    feature_df['number_of_words'] = data['text'].apply(lambda x\n",
    "                                                       : len(word_tokenize(str(x))))\n",
    " \n",
    "    return feature_df\n",
    "\n",
    "feature_df = get_number_of_words(feature_df, data)\n",
    "feature_df['number_of_words'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4\n",
       "1    3\n",
       "2    7\n",
       "3    3\n",
       "4    2\n",
       "Name: number_of_white_spaces, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_number_of_whitespaces(feature_df, data):\n",
    "    # The below code line will generate list of white spaces\n",
    "    # in each row and add the length of that list into\n",
    "    # the columns `number_of_white_spaces`\n",
    " \n",
    "    feature_df['number_of_white_spaces'] = data['text']. \\\n",
    "        apply(lambda x: len([ch for ch in str(x) if ch.isspace()]))\n",
    " \n",
    "    return feature_df\n",
    " \n",
    "feature_df = get_number_of_whitespaces(feature_df, data)\n",
    "feature_df['number_of_white_spaces'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LS</th>\n",
       "      <th>TO</th>\n",
       "      <th>VBN</th>\n",
       "      <th>''</th>\n",
       "      <th>WP</th>\n",
       "      <th>UH</th>\n",
       "      <th>VBG</th>\n",
       "      <th>JJ</th>\n",
       "      <th>VBZ</th>\n",
       "      <th>--</th>\n",
       "      <th>...</th>\n",
       "      <th>CC</th>\n",
       "      <th>CD</th>\n",
       "      <th>POS</th>\n",
       "      <th>num_of_unique_punctuations</th>\n",
       "      <th>number_of_capital_words</th>\n",
       "      <th>number_of_small_words</th>\n",
       "      <th>number_of_alphabets</th>\n",
       "      <th>number_of_digits</th>\n",
       "      <th>number_of_words</th>\n",
       "      <th>number_of_white_spaces</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    LS   TO  VBN   ''   WP   UH  VBG   JJ  VBZ   --  ...   CC   CD  POS  \\\n",
       "0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  ...  0.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "   num_of_unique_punctuations  number_of_capital_words  number_of_small_words  \\\n",
       "0                           0                        1                      4   \n",
       "1                           0                        1                      3   \n",
       "2                           1                        1                      7   \n",
       "3                           1                        1                      3   \n",
       "4                           0                        1                      2   \n",
       "\n",
       "   number_of_alphabets  number_of_digits  number_of_words  \\\n",
       "0                   19                 0                5   \n",
       "1                   18                 0                4   \n",
       "2                   28                 0                9   \n",
       "3                   14                 0                5   \n",
       "4                   13                 0                3   \n",
       "\n",
       "   number_of_white_spaces  \n",
       "0                       4  \n",
       "1                       3  \n",
       "2                       7  \n",
       "3                       3  \n",
       "4                       2  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
